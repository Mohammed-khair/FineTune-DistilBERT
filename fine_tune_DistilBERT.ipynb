{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_7XvPby28q0"
      },
      "source": [
        "# Fine-Tuning DistilBert for classification of  NSFW prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52inNsXn2uS0"
      },
      "source": [
        "We will first install and import some libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CO-J7QoD2qON"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSVQZlyUE3_2"
      },
      "source": [
        "## Import the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY6TqoI4oWoF"
      },
      "source": [
        "First, we will import the training data from [HuggingFace](https://huggingface.co/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JUjl9_Q8obMU"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"thefcraft/civitai-stable-diffusion-337k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdBr3v4lp-bO"
      },
      "source": [
        "Extract the training data from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sAObr8lSpCLs"
      },
      "outputs": [],
      "source": [
        "data = dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCF9sU_GA0jX"
      },
      "source": [
        "Number of examples in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrYlsFR0Aziv",
        "outputId": "5b1293f9-41bf-4910-c28a-a2bc368dcb92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "327138"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLVlbzClExHW"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3IrWAaxrWKl"
      },
      "source": [
        "We will then extract the prompts, negative prompts, and the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lI1zNQM_pih2"
      },
      "outputs": [],
      "source": [
        "# Extract the prompts and negative prompts\n",
        "prompts = [d['prompt'] for d in data]\n",
        "neg_prompts = [d['negativePrompt'] for d in data]\n",
        "labels = [d['nsfw'] for d in data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhIjwNyprP4g"
      },
      "source": [
        "Display a NSFW example of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8gTvrAirjzK",
        "outputId": "6b8732e7-db7b-430f-9bea-81f5e8b7117d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NSFW: True\n",
            "Prompt: masterpiece, best quality, highres, absurdres, concept art, character profile, reference sheet, turnaround, logo, 1girl, revealing clothes, nipples, topless, exhibitionism, school uniform\n",
            "Negative Prompt: EasyNegative, extra fingers, fewer fingers\n"
          ]
        }
      ],
      "source": [
        "print(\"NSFW: \" + str(labels[1]))\n",
        "print(\"Prompt: \" + prompts[1])\n",
        "print(\"Negative Prompt: \" + neg_prompts[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKobsP6AzUX3"
      },
      "source": [
        "Display a NON - NSFW example of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp9O7KZ3yTIQ",
        "outputId": "599333e1-846c-46c0-a5c5-1648072e2825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NSFW: False\n",
            "Prompt: (8k, RAW photo, best quality, masterpiece:1.2), (realistic, photo-realistic:1.37),<lora:koreanDollLikeness_v10:0.5> ,<lora:arknightsTexasThe_v10:1>,omertosa,1girl,(Kpop idol), (aegyo sal:1),cute,cityscape, night, rain, wet, professional lighting, photon mapping, radiosity, physically-based rendering,\n",
            "Negative Prompt: EasyNegative, paintings, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, glans,extra fingers,fewer fingers,strange fingers,bad hand\n"
          ]
        }
      ],
      "source": [
        "print(\"NSFW: \" + str(labels[7]))\n",
        "print(\"Prompt: \" + prompts[7])\n",
        "print(\"Negative Prompt: \" + neg_prompts[7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5kNoEQw11_A"
      },
      "source": [
        "We will combine the two prompts into one sentence of the following format:\n",
        "\n",
        "\"Positive prompt: `pos_prompt`. Negative prompt: `neg_prompt`\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nhnm-_7kyzk7"
      },
      "outputs": [],
      "source": [
        "# Combine positive and negative prompts\n",
        "prompts_combined = []\n",
        "\n",
        "for pos_prompt, neg_prompt in zip(prompts, neg_prompts):\n",
        "    combined_prompt = f\"Positive prompt: {pos_prompt}. Negative prompt: {neg_prompt}\"\n",
        "    prompts_combined.append(combined_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9KkH6SlA2E8j"
      },
      "outputs": [],
      "source": [
        "# Load DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Tokenization\n",
        "inputs = tokenizer(prompts_combined, padding=True, truncation=True, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki5egGamB1mX"
      },
      "source": [
        "The inputs will have two rows:\n",
        "* input ids:\n",
        "* attention masks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ikq4w--Dxo",
        "outputId": "0f993d4e-74c3-4a8d-a362-933cd44a643d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(327138, 512), dtype=int32, numpy=\n",
              "array([[  101,  3893, 25732, ...,     0,     0,     0],\n",
              "       [  101,  3893, 25732, ...,     0,     0,     0],\n",
              "       [  101,  3893, 25732, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  3893, 25732, ...,     0,     0,     0],\n",
              "       [  101,  3893, 25732, ...,     0,     0,     0],\n",
              "       [  101,  3893, 25732, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(327138, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])>}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQbXE1XMBRCW"
      },
      "source": [
        "split the data to a training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DmKzmQ9V_cno"
      },
      "outputs": [],
      "source": [
        "input_ids = inputs['input_ids'].numpy()\n",
        "attention_mask = inputs['attention_mask'].numpy()\n",
        "labels = [int(x) for x in labels] # convert bool to int\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "input_ids_train, input_ids_test, attention_mask_train, attention_mask_test, labels_train, labels_test = train_test_split(\n",
        "    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RNt02gBoBUZN"
      },
      "outputs": [],
      "source": [
        "# Now, you can convert the split data back to TensorFlow tensors if needed\n",
        "# input_ids\n",
        "input_ids_train_tensor = tf.convert_to_tensor(input_ids_train)\n",
        "input_ids_test_tensor = tf.convert_to_tensor(input_ids_test)\n",
        "\n",
        "#attenstion_mask\n",
        "attention_mask_train_tensor = tf.convert_to_tensor(attention_mask_train)\n",
        "attention_mask_test_tensor = tf.convert_to_tensor(attention_mask_test)\n",
        "\n",
        "#labels\n",
        "train_labels_tensor = tf.convert_to_tensor(labels_train)\n",
        "test_labels_tensor = tf.convert_to_tensor(labels_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HGCFxfUEh2Y"
      },
      "source": [
        "## Create the DistilBERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IZhELcLEX5f",
        "outputId": "6a0c9188-cb8d-46c0-f380-bb21aa918681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Build the DistilBERT-based model\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJu8l_5QJbC6",
        "outputId": "dca96934-f5e9-4462-cb95-b064c44c04ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Model.summary of <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x0000024531E77910>>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RniwsihZE7yF"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "wf1q5TtBFt7F",
        "outputId": "1a62bd65-02ef-4176-a001-4d576cfd218b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "   20/26171 [..............................] - ETA: 69:24:47 - loss: 0.7188 - accuracy: 0.5063"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    {'input_ids': input_ids_train_tensor, 'attention_mask': attention_mask_train_tensor},\n",
        "    train_labels_tensor,\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9fGBR7OK-JV"
      },
      "outputs": [],
      "source": [
        "model.save('models/model.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
